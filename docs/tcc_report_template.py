# -*- coding: utf-8 -*-
"""HTML template for the comprehensive TCC report."""

def build_html(c_metrics, c_cm, c_radar, c_lt, c_tmpl, c_pipe, OS, HD, BG):
    def fmt(m):
        if m is None: return "‚Äî"
        if abs(m)<1: return f"{m*60:.1f}s"
        if abs(m)<60: return f"{m:.1f}min"
        if abs(m)<1440: return f"{m/60:.1f}h"
        return f"{m/1440:.1f}d"

    CSS = """
    :root{--bg:#0a0a1a;--surface:#151530;--card:#1c1c40;--emerald:#27ae60;--blue:#3498db;--red:#e74c3c;--gold:#f39c12;--text:#e0e0e0;--muted:#7f8c8d;}
    *{box-sizing:border-box;margin:0;padding:0}
    body{font-family:'Inter',sans-serif;background:var(--bg);color:var(--text);line-height:1.8}
    .hero{background:linear-gradient(135deg,#0f2027,#203a43,#2c5364);padding:80px 20px;text-align:center;border-bottom:4px solid var(--emerald)}
    .hero h1{font-size:3rem;font-weight:900;background:linear-gradient(90deg,#27ae60,#3498db,#9b59b6);-webkit-background-clip:text;-webkit-text-fill-color:transparent}
    .hero p{font-size:1.2rem;color:rgba(255,255,255,.7);margin-top:10px}
    .hero .sub{font-size:.85rem;color:rgba(255,255,255,.4);margin-top:8px}
    .container{max-width:1200px;margin:0 auto;padding:40px 20px}
    section{background:var(--surface);border-radius:16px;padding:45px;margin-bottom:40px;border:1px solid rgba(255,255,255,.05);box-shadow:0 8px 32px rgba(0,0,0,.3)}
    h2{color:var(--emerald);font-weight:800;font-size:1.8rem;border-bottom:2px solid rgba(39,174,96,.3);padding-bottom:12px;margin-bottom:25px}
    h3{color:var(--blue);font-weight:700;font-size:1.3rem;margin:30px 0 15px}
    h4{color:var(--gold);font-weight:600;margin:20px 0 10px}
    p{margin-bottom:15px;font-size:15px}
    .img-c{text-align:center;margin:25px 0}
    .img-c img{max-width:100%;border-radius:12px;border:1px solid rgba(255,255,255,.1)}
    table{width:100%;border-collapse:collapse;margin:20px 0;font-size:14px}
    th{background:rgba(39,174,96,.15);color:var(--emerald);padding:14px 12px;text-align:left;font-weight:700;border-bottom:2px solid rgba(39,174,96,.3)}
    td{padding:12px;border-bottom:1px solid rgba(255,255,255,.05)}
    tr:hover{background:rgba(255,255,255,.03)}
    .kpi-row{display:flex;gap:20px;flex-wrap:wrap;margin:25px 0}
    .kpi{flex:1;min-width:140px;background:var(--card);padding:22px;border-radius:12px;text-align:center;border:1px solid rgba(255,255,255,.08)}
    .kpi .v{font-size:2rem;font-weight:800;margin:6px 0}
    .kpi .l{font-size:.72rem;text-transform:uppercase;letter-spacing:1.5px;color:var(--muted);font-weight:600}
    .green .v{color:var(--emerald)}.blue .v{color:var(--blue)}.red .v{color:var(--red)}.gold .v{color:var(--gold)}
    .note{background:rgba(52,152,219,.1);border-left:4px solid var(--blue);padding:15px 20px;border-radius:0 8px 8px 0;margin:20px 0;font-size:14px}
    .warn{background:rgba(231,76,60,.1);border-left:4px solid var(--red);padding:15px 20px;border-radius:0 8px 8px 0;margin:20px 0;font-size:14px}
    .badge{display:inline-block;padding:3px 10px;border-radius:12px;font-size:11px;font-weight:700}
    .bg{background:rgba(39,174,96,.2);color:#27ae60}.br{background:rgba(231,76,60,.2);color:#e74c3c}.bb{background:rgba(52,152,219,.2);color:#3498db}
    code{background:rgba(255,255,255,.1);padding:2px 8px;border-radius:4px;font-size:12px;font-family:'Fira Code',monospace}
    ol,ul{margin:10px 0 15px 25px}
    li{margin-bottom:8px}
    .flex{display:flex;gap:30px;flex-wrap:wrap}.col{flex:1;min-width:280px}
    .step-box{background:var(--card);border-radius:12px;padding:20px;margin:15px 0;border-left:4px solid var(--emerald)}
    .step-box h4{margin-top:0;color:var(--emerald)}
    @media(max-width:800px){.flex{flex-direction:column}.kpi-row{flex-direction:column}}
    """

    return f"""<!DOCTYPE html>
<html lang="pt-BR"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1">
<title>LogGPT ‚Äî Relat√≥rio Completo TCC</title>
<link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;700;800;900&display=swap" rel="stylesheet">
<style>{CSS}</style></head><body>

<div class="hero">
<h1>üß† LogGPT: Detec√ß√£o Proativa de Anomalias em Logs</h1>
<p>Trabalho de Conclus√£o de Curso ‚Äî Relat√≥rio T√©cnico Completo</p>
<p class="sub">An√°lise comparativa em 3 datasets: OpenStack ¬∑ HDFS ¬∑ BGL | Modelo baseado em GPT-2 (Causal Language Model)</p>
</div>

<div class="container">

<!-- 1. INTRODU√á√ÉO -->
<section>
<h2>1. Introdu√ß√£o e Contexto</h2>
<p>Sistemas de software modernos ‚Äî como plataformas de <strong>cloud computing</strong>, sistemas de <strong>armazenamento distribu√≠do</strong> e <strong>supercomputadores</strong> ‚Äî geram milh√µes de linhas de log diariamente. Essas mensagens registram o comportamento interno do sistema: cada opera√ß√£o, cada erro, cada alerta.</p>
<p>O desafio √©: <strong>como detectar automaticamente que algo est√° errado, antes que o sistema falhe?</strong> A abordagem tradicional depende de regras manuais ("se aparecer a palavra ERROR, alerte"), mas isso √© fr√°gil e n√£o captura padr√µes sutis que antecedem falhas catastr√≥ficas.</p>

<h3>O que √© o LogGPT?</h3>
<p>O <strong>LogGPT</strong> √© um modelo de intelig√™ncia artificial baseado na arquitetura <strong>GPT-2</strong> (a mesma fam√≠lia do ChatGPT) adaptado especificamente para analisar logs de sistemas computacionais. Em vez de aprender a prever a pr√≥xima palavra em textos humanos, o LogGPT aprende a <strong>prever o pr√≥ximo evento de log</strong> em uma sequ√™ncia de opera√ß√µes do sistema.</p>

<div class="note">
üí° <strong>Analogia simples:</strong> Imagine um m√©dico que, ap√≥s anos observando batimentos card√≠acos normais, consegue identificar instantaneamente quando um ritmo est√° "fora do padr√£o". O LogGPT faz o mesmo com logs: ele aprende o padr√£o "saud√°vel" e identifica quando o sistema come√ßa a se comportar de forma an√¥mala.
</div>

<h3>Objetivo do Trabalho</h3>
<p>Este trabalho avalia a capacidade do LogGPT de:</p>
<ol>
<li><strong>Detectar anomalias</strong> ‚Äî identificar sess√µes que cont√™m falhas reais</li>
<li><strong>Antecipar falhas</strong> ‚Äî alertar <em>antes</em> do erro acontecer (lead time)</li>
<li><strong>Generalizar</strong> ‚Äî funcionar em diferentes dom√≠nios (cloud, storage, HPC)</li>
</ol>

<h3>Papers e Refer√™ncias</h3>
<table>
<tr><th>Refer√™ncia</th><th>Contribui√ß√£o</th></tr>
<tr><td>Guo et al. (2021) ‚Äî <em>"LogGPT: Log Anomaly Detection via GPT"</em></td><td>Proposta original do m√©todo, usando GPT-2 como modelo causal de linguagem para detec√ß√£o de anomalias em logs estruturados.</td></tr>
<tr><td>He et al. (2020) ‚Äî <em>"Loghub: A Large Collection of System Log Datasets"</em></td><td>Reposit√≥rio de datasets de logs usados como benchmark (OpenStack, HDFS, BGL).</td></tr>
<tr><td>Du et al. (2017) ‚Äî <em>"DeepLog: Anomaly Detection and Diagnosis from System Logs through Deep Learning"</em></td><td>Trabalho seminal que introduziu deep learning para detec√ß√£o de anomalias em logs, usando LSTM.</td></tr>
<tr><td>He et al. (2017) ‚Äî <em>"Drain: An Online Log Parsing Approach"</em></td><td>Algoritmo de parsing que converte logs brutos em templates estruturados (EventIds).</td></tr>
<tr><td>Radford et al. (2019) ‚Äî <em>"Language Models are Unsupervised Multitask Learners"</em> (GPT-2)</td><td>Arquitetura base do modelo, demonstrando que modelos causais de linguagem podem capturar padr√µes sequenciais complexos.</td></tr>
</table>
</section>

<!-- 2. METODOLOGIA -->
<section>
<h2>2. Metodologia ‚Äî Passo a Passo</h2>
<p>Abaixo explicamos cada etapa do processo, desde os logs brutos at√© a detec√ß√£o final, de forma que qualquer pessoa possa entender.</p>

<div class="img-c"><img src="data:image/png;base64,{c_pipe}" alt="Pipeline"></div>

<div class="step-box"><h4>Etapa 1 ‚Äî Coleta de Logs Brutos</h4>
<p>Os logs s√£o coletados diretamente dos servidores. Cada linha cont√©m um timestamp, n√≠vel de severidade (INFO, WARNING, ERROR), o componente que gerou o log e a mensagem em si.</p>
<p><code>2018-06-26 03:34:27 INFO nova.compute: Instance i-00000001 launched successfully</code></p>
</div>

<div class="step-box"><h4>Etapa 2 ‚Äî Log Parsing (Drain)</h4>
<p>O algoritmo <strong>Drain</strong> converte cada mensagem de log em um <strong>template</strong> (EventId), substituindo valores vari√°veis por wildcards <code>&lt;*&gt;</code>. Isso reduz milh√µes de mensagens √∫nicas para dezenas de templates reutiliz√°veis.</p>
<p>Exemplo: <code>"Instance i-00000001 launched"</code> ‚Üí Template: <code>"Instance &lt;*&gt; launched"</code> ‚Üí EventId: <code>e17b68d6</code></p>
</div>

<div class="step-box"><h4>Etapa 3 ‚Äî Agrupamento em Sess√µes</h4>
<p>Os logs s√£o agrupados por identificador de sess√£o:</p>
<ul>
<li><strong>OpenStack:</strong> por <code>test_id</code> (cada teste do Tempest gera uma sess√£o)</li>
<li><strong>HDFS:</strong> por <code>block_id</code> (cada bloco de dados tem sua sequ√™ncia)</li>
<li><strong>BGL:</strong> por <code>node_id</code> + janela temporal (sliding window de 20 eventos)</li>
</ul>
<p>Uma sess√£o vira uma sequ√™ncia de EventIds: <code>"e17b68d6 96691030 f7725eaf b8be6124"</code></p>
</div>

<div class="step-box"><h4>Etapa 4 ‚Äî Treinamento do Modelo (Causal LM)</h4>
<p>O modelo GPT-2 √© treinado <strong>apenas em sess√µes normais</strong> (sem falha). Ele aprende a prever "qual ser√° o pr√≥ximo evento?" dado o contexto anterior. Ap√≥s o treino, ele sabe qual √© o comportamento "normal" do sistema.</p>
<p><strong>Bibliotecas:</strong> PyTorch, HuggingFace Transformers, Polars (processamento de dados), Scikit-learn (m√©tricas).</p>
</div>

<div class="step-box"><h4>Etapa 5 ‚Äî Detec√ß√£o (Top-K)</h4>
<p>Na fase de detec√ß√£o, o modelo recebe cada sess√£o de teste e, para cada evento, verifica se o evento real est√° entre as <strong>Top-K predi√ß√µes mais prov√°veis</strong> (K=5). Se o evento real N√ÉO estiver no Top-5, o modelo marca aquele ponto como <strong>an√¥malo</strong>.</p>
<p>Se qualquer ponto da sess√£o for an√¥malo, toda a sess√£o √© classificada como an√¥mala.</p>
</div>

<div class="step-box"><h4>Etapa 6 ‚Äî C√°lculo do Lead Time</h4>
<p>O <strong>lead time</strong> mede quanto tempo <em>antes</em> do primeiro erro real o modelo detectou a anomalia. Usamos timestamps reais (resolu√ß√£o de microssegundos) para calcular essa diferen√ßa em minutos/horas.</p>
<p>Lead Time = Timestamp do 1¬∫ Erro Real ‚àí Timestamp da Detec√ß√£o pelo Modelo</p>
</div>

<h3>Tecnologias Utilizadas</h3>
<table>
<tr><th>Tecnologia</th><th>Vers√£o</th><th>Uso</th></tr>
<tr><td>Python</td><td>3.10+</td><td>Linguagem principal</td></tr>
<tr><td>PyTorch</td><td>2.x</td><td>Framework de deep learning</td></tr>
<tr><td>HuggingFace Transformers</td><td>4.x</td><td>Tokenizer e config do GPT-2</td></tr>
<tr><td>DistilGPT-2</td><td>‚Äî</td><td>Tokenizer base (vocabul√°rio de 50257 tokens)</td></tr>
<tr><td>Polars</td><td>0.20+</td><td>Processamento eficiente de DataFrames</td></tr>
<tr><td>Pandas</td><td>2.x</td><td>An√°lise de dados e gera√ß√£o de relat√≥rios</td></tr>
<tr><td>Scikit-learn</td><td>1.x</td><td>M√©tricas (precision, recall, F1, confusion matrix)</td></tr>
<tr><td>Matplotlib + Seaborn</td><td>3.x / 0.13</td><td>Visualiza√ß√µes e gr√°ficos</td></tr>
</table>
</section>

<!-- 3. DATASETS -->
<section>
<h2>3. Datasets ‚Äî Descri√ß√£o e Particularidades</h2>
<p>Utilizamos tr√™s datasets p√∫blicos do reposit√≥rio <a href="https://github.com/logpai/loghub" style="color:var(--blue)">Loghub</a>, cada um representando um cen√°rio distinto de infraestrutura computacional.</p>

<table>
<tr><th>Caracter√≠stica</th><th style="color:#27ae60">üü¢ OpenStack</th><th style="color:#3498db">üîµ HDFS</th><th style="color:#e74c3c">üî¥ BGL</th></tr>
<tr><td><strong>Dom√≠nio</strong></td><td>Cloud Computing (IaaS)</td><td>Armazenamento Distribu√≠do</td><td>Supercomputador HPC</td></tr>
<tr><td><strong>Fonte</strong></td><td>Loghub</td><td>Loghub</td><td>Loghub</td></tr>
<tr><td><strong>Per√≠odo</strong></td><td>Jun-Jul 2018</td><td>Nov 2008</td><td>Jun 2005 ‚Äî Jan 2006</td></tr>
<tr><td><strong>Total de Logs</strong></td><td>~424K linhas</td><td>~11M linhas</td><td>~4.7M linhas</td></tr>
<tr><td><strong>Sess√µes</strong></td><td>420 (test_ids)</td><td>~575K (block_ids)</td><td>~370K (sliding windows)</td></tr>
<tr><td><strong>Templates √önicos</strong></td><td>30</td><td>29</td><td><span class="badge br">242</span></td></tr>
<tr><td><strong>Agrupamento</strong></td><td>Por teste (test_id)</td><td>Por bloco HDFS (block_id)</td><td>Por n√≥ + janela temporal</td></tr>
<tr><td><strong>Tipos de Falha</strong></td><td>Erros de API, exce√ß√µes Python, timeouts</td><td>I/O exceptions, interrup√ß√µes</td><td>Hardware: mem√≥ria, cache, rede torus</td></tr>
<tr><td><strong>Resolu√ß√£o Temporal</strong></td><td>Microssegundos</td><td>Microssegundos</td><td>Segundos (Unix epoch)</td></tr>
<tr><td><strong>Modelo Usado</strong></td><td>Treinado localmente</td><td>Treinado localmente</td><td><span class="badge br">Modelo OpenStack (transfer√™ncia)</span></td></tr>
</table>

<h3>üü¢ OpenStack ‚Äî Cloud Computing</h3>
<p>O OpenStack √© uma plataforma open-source de cloud computing. O dataset cont√©m logs de testes automatizados (Tempest) que exercitam APIs de cria√ß√£o de inst√¢ncias, volumes, redes e imagens. As sess√µes s√£o relativamente curtas (dezenas a centenas de eventos) e os templates s√£o bem definidos. <strong>Ideal para o LogGPT</strong> pois os padr√µes sequenciais s√£o claros e consistentes.</p>

<h3>üîµ HDFS ‚Äî Hadoop Distributed File System</h3>
<p>O HDFS √© o sistema de arquivos distribu√≠do do Hadoop. Cada bloco de dados gera uma sequ√™ncia de log (aloca√ß√£o ‚Üí replica√ß√£o ‚Üí servir leituras). As falhas s√£o predominantemente de I/O (rede, disco). O dataset √© muito grande (~575K blocos), o que d√° ao modelo bastante dados para aprender. <strong>Desafio:</strong> muitas sess√µes muito curtas (2-5 eventos).</p>

<h3>üî¥ BGL ‚Äî Blue Gene/L Supercomputer</h3>
<p>O BGL √© um supercomputador IBM com 131.072 processadores. O dataset registra falhas de hardware: erros de mem√≥ria, cache, rede torus, panicles de kernel. √â fundamentalmente diferente dos outros dois datasets.</p>
<div class="warn">
‚ö†Ô∏è <strong>Por que o BGL n√£o funcionou bem:</strong> O modelo foi treinado com padr√µes de OpenStack (software) e testado em logs de BGL (hardware). Esses dom√≠nios s√£o t√£o diferentes que o modelo n√£o consegue distinguir o "normal" do "an√¥malo" ‚Äî ele acha tudo estranho. O BGL possui <strong>242 templates √∫nicos</strong> (8x mais que os outros datasets), e esses templates descrevem eventos de hardware que nunca apareceram no treinamento. O resultado √© um modelo que classifica quase tudo como anomalia (recall=100% mas precision=48.9%).
</div>
</section>

<!-- 4. RESULTADOS COMPARATIVOS -->
<section>
<h2>4. Resultados Comparativos</h2>

<div class="kpi-row">
<div class="kpi green"><div class="l">OpenStack F1</div><div class="v">{OS['f1']*100:.1f}%</div><div class="l">Precision {OS['precision']*100:.1f}% ¬∑ Recall {OS['recall']*100:.1f}%</div></div>
<div class="kpi blue"><div class="l">HDFS F1</div><div class="v">{HD['f1']*100:.1f}%</div><div class="l">Precision {HD['precision']*100:.1f}% ¬∑ Recall {HD['recall']*100:.1f}%</div></div>
<div class="kpi red"><div class="l">BGL F1</div><div class="v">{BG['f1']*100:.1f}%</div><div class="l">Precision {BG['precision']*100:.1f}% ¬∑ Recall {BG['recall']*100:.1f}%</div></div>
</div>

<h3>4.1 M√©tricas de Classifica√ß√£o</h3>
<div class="img-c"><img src="data:image/png;base64,{c_metrics}" alt="M√©tricas"></div>

<h3>4.2 Radar Comparativo</h3>
<div class="img-c"><img src="data:image/png;base64,{c_radar}" alt="Radar"></div>

<h3>4.3 Matrizes de Confus√£o</h3>
<div class="img-c"><img src="data:image/png;base64,{c_cm}" alt="Confusion Matrix"></div>

<h3>Interpreta√ß√£o das M√©tricas</h3>
<table>
<tr><th>M√©trica</th><th>O que significa (linguagem simples)</th></tr>
<tr><td><strong>Precision</strong></td><td>"Dos alarmes que o modelo disparou, quantos eram falhas reais?" ‚Äî Alta precision = poucos alarmes falsos.</td></tr>
<tr><td><strong>Recall</strong></td><td>"Das falhas reais que existiam, quantas o modelo encontrou?" ‚Äî Alto recall = poucas falhas escaparam.</td></tr>
<tr><td><strong>F1-Score</strong></td><td>M√©dia harm√¥nica de Precision e Recall. √â a m√©trica principal ‚Äî quanto maior, melhor o equil√≠brio.</td></tr>
<tr><td><strong>Accuracy</strong></td><td>"No geral, quantas classifica√ß√µes estavam corretas?" ‚Äî Pode ser enganosa se os dados forem desbalanceados.</td></tr>
</table>
</section>

<!-- 5. OPENSTACK DETALHADO -->
<section>
<h2>5. OpenStack ‚Äî An√°lise Detalhada</h2>
<div class="kpi-row">
<div class="kpi green"><div class="l">True Positives</div><div class="v">{OS['tp']}</div></div>
<div class="kpi blue"><div class="l">True Negatives</div><div class="v">{OS['tn']}</div></div>
<div class="kpi gold"><div class="l">False Positives</div><div class="v">{OS['fp']}</div></div>
<div class="kpi red"><div class="l">False Negatives</div><div class="v">{OS['fn']}</div></div>
</div>
<p>O OpenStack obteve os <strong>melhores resultados</strong> entre os tr√™s datasets. Com apenas <strong>5 falsos positivos</strong> e <strong>7 falsos negativos</strong> em 420 sess√µes, o modelo demonstra uma capacidade excepcional de distinguir opera√ß√µes normais de falhas reais.</p>
<p>Os tipos de falha detectados incluem: erros de API REST (HTTP 500), exce√ß√µes Python (<code>TypeError</code>, <code>KeyError</code>), timeouts de opera√ß√µes e falhas de cria√ß√£o/destrui√ß√£o de recursos cloud.</p>

<h3>Lead Time ‚Äî Antecipa√ß√£o</h3>
<div class="kpi-row">
<div class="kpi green"><div class="l">Antecipa√ß√£o M√©dia</div><div class="v">{fmt(OS['lt_mean_min'])}</div></div>
<div class="kpi blue"><div class="l">Mediana</div><div class="v">{fmt(OS['lt_median_min'])}</div></div>
<div class="kpi gold"><div class="l">M√°xima</div><div class="v">{fmt(OS['lt_max_min'])}</div></div>
<div class="kpi green"><div class="l">% Antecipadas</div><div class="v">{OS['lt_pct_ant']:.0f}%</div></div>
</div>
<p>Em <strong>{OS['lt_pct_ant']:.0f}%</strong> das sess√µes detectadas, o modelo alertou <em>antes</em> do primeiro erro real ‚Äî com uma m√©dia de <strong>{fmt(OS['lt_mean_min'])}</strong> de anteced√™ncia. Isso demonstra que o LogGPT n√£o apenas detecta falhas, mas as <strong>antecipa</strong>, dando tempo para a√ß√µes corretivas antes que o impacto se materialize.</p>
</section>

<!-- 6. HDFS DETALHADO -->
<section>
<h2>6. HDFS ‚Äî An√°lise Detalhada</h2>
<div class="kpi-row">
<div class="kpi green"><div class="l">True Positives</div><div class="v">{HD['tp']:,}</div></div>
<div class="kpi blue"><div class="l">True Negatives</div><div class="v">{HD['tn']:,}</div></div>
<div class="kpi gold"><div class="l">False Positives</div><div class="v">{HD['fp']:,}</div></div>
<div class="kpi red"><div class="l">False Negatives</div><div class="v">{HD['fn']:,}</div></div>
</div>
<p>O HDFS processou <strong>{HD['total_sessions']:,} sess√µes de teste</strong> ‚Äî uma escala 170x maior que o OpenStack. Mesmo assim, manteve <strong>Precision de 95%</strong> com <strong>Recall de 82.3%</strong>. Os 2.983 falsos negativos representam blocos onde a anomalia era sutil demais para o modelo Top-K capturar (sess√µes muito curtas com poucos eventos).</p>

<h3>Lead Time ‚Äî Antecipa√ß√£o</h3>
<div class="kpi-row">
<div class="kpi green"><div class="l">Antecipa√ß√£o M√©dia</div><div class="v">{fmt(HD['lt_mean_min'])}</div></div>
<div class="kpi blue"><div class="l">Mediana</div><div class="v">{fmt(HD['lt_median_min'])}</div></div>
<div class="kpi gold"><div class="l">M√°xima</div><div class="v">{fmt(HD['lt_max_min'])}</div></div>
<div class="kpi green"><div class="l">% Antecipadas</div><div class="v">{HD['lt_pct_ant']:.0f}%</div></div>
</div>
<p>No HDFS, o modelo conseguiu antecipar falhas com at√© <strong>{fmt(HD['lt_max_min'])}</strong> de anteced√™ncia. A m√©dia de <strong>{fmt(HD['lt_mean_min'])}</strong> indica que, em muitos casos, o modelo detecta padr√µes pr√©-falha horas antes da cascata de I/O errors se materializar.</p>
</section>

<!-- 7. BGL ‚Äî POR QUE FALHOU -->
<section>
<h2>7. BGL ‚Äî An√°lise e Motivos do Insucesso</h2>
<div class="kpi-row">
<div class="kpi red"><div class="l">Precision</div><div class="v">{BG['precision']*100:.1f}%</div><div class="l">Quase metade s√£o alarmes falsos</div></div>
<div class="kpi gold"><div class="l">Recall</div><div class="v">{BG['recall']*100:.0f}%</div><div class="l">Encontrou tudo (pois alertou tudo)</div></div>
<div class="kpi red"><div class="l">F1-Score</div><div class="v">{BG['f1']*100:.1f}%</div><div class="l">Muito abaixo do aceit√°vel</div></div>
</div>

<h3>O que aconteceu?</h3>
<p>O BGL obteve <strong>100% de recall</strong> mas apenas <strong>48.9% de precision</strong>. Isso significa que o modelo <strong>classificou praticamente TODAS as sess√µes como an√¥malas</strong>, acertando as que realmente eram an√¥malas mas tamb√©m gerando uma quantidade massiva de falsos positivos.</p>

<h3>Causas Ra√≠z do Insucesso</h3>

<h4>1. Incompatibilidade de Dom√≠nio (Transfer Learning Ineficaz)</h4>
<p>O modelo foi treinado em logs de <strong>OpenStack</strong> (software de cloud) e testado em logs de <strong>BGL</strong> (hardware de supercomputador). S√£o dom√≠nios completamente diferentes:</p>
<ul>
<li><strong>OpenStack:</strong> HTTP requests, API calls, inst√¢ncias de VMs, opera√ß√µes CRUD</li>
<li><strong>BGL:</strong> Erros de mem√≥ria DDR, parity errors, cache ECC, rede torus, kernel panics</li>
</ul>
<p>O modelo nunca viu esses tipos de eventos durante o treinamento, ent√£o qualquer sequ√™ncia do BGL parece "an√¥mala".</p>

<h4>2. Diversidade Excessiva de Templates</h4>
<div class="img-c"><img src="data:image/png;base64,{c_tmpl}" alt="Templates"></div>
<p>O BGL possui <strong>242 templates √∫nicos</strong> ‚Äî 8 vezes mais que o OpenStack (30) ou HDFS (29). Essa diversidade extrema significa que o vocabul√°rio do BGL √© muito mais rico e complexo, tornando imposs√≠vel para um modelo treinado em outro dom√≠nio fazer previs√µes corretas.</p>

<h4>3. Natureza Diferente dos Eventos</h4>
<p>No OpenStack e HDFS, as anomalias s√£o <em>perturba√ß√µes</em> no padr√£o normal (um erro HTTP no meio de opera√ß√µes normais). No BGL, os eventos de "erro" e "normal" s√£o frequentemente tipos de log completamente diferentes (registros de hardware vs. mensagens de aplica√ß√£o), e n√£o perturba√ß√µes no mesmo fluxo.</p>

<h4>4. Modelo com Janela Fixa (Sliding Window)</h4>
<p>Enquanto OpenStack e HDFS usam sess√µes naturais (test_id, block_id), o BGL foi segmentado com <strong>janelas deslizantes de 20 eventos</strong>. Isso pode quebrar o contexto da sequ√™ncia e misturar eventos que n√£o pertencem ao mesmo incidente.</p>

<div class="warn">
‚ö†Ô∏è <strong>Conclus√£o BGL:</strong> Para o BGL funcionar adequadamente, seria necess√°rio <strong>re-treinar o modelo</strong> diretamente com logs normais do BGL. A transfer√™ncia de aprendizado entre dom√≠nios t√£o diferentes (software ‚Üí hardware) n√£o se sustenta com a abordagem Causal LM pura.
</div>
</section>

<!-- 8. LEAD TIME COMPARATIVO -->
<section>
<h2>8. Lead Time ‚Äî An√°lise Comparativa de Antecipa√ß√£o</h2>
<p>O <strong>lead time</strong> √© a capacidade preditiva mais valiosa do LogGPT: quanto tempo antes do primeiro erro real o modelo consegue alertar sobre a anomalia.</p>

<div class="img-c"><img src="data:image/png;base64,{c_lt}" alt="Lead Time"></div>

<table>
<tr><th>M√©trica de Lead Time</th><th style="color:#27ae60">OpenStack</th><th style="color:#3498db">HDFS</th><th style="color:#e74c3c">BGL</th></tr>
<tr><td>M√©dia (sess√µes antecipadas)</td><td><strong>{fmt(OS['lt_mean_min'])}</strong></td><td><strong>{fmt(HD['lt_mean_min'])}</strong></td><td>‚Äî</td></tr>
<tr><td>Mediana</td><td>{fmt(OS['lt_median_min'])}</td><td>{fmt(HD['lt_median_min'])}</td><td>‚Äî</td></tr>
<tr><td>M√°ximo</td><td>{fmt(OS['lt_max_min'])}</td><td>{fmt(HD['lt_max_min'])}</td><td>‚Äî</td></tr>
<tr><td>% Sess√µes Antecipadas</td><td>{OS['lt_pct_ant']:.0f}%</td><td>{HD['lt_pct_ant']:.0f}%</td><td>N/A (modelo inv√°lido)</td></tr>
</table>

<div class="note">
üìä <strong>Interpreta√ß√£o:</strong> No OpenStack, o modelo tipicamente antecipa falhas em ~3.5 minutos ‚Äî tempo suficiente para um sistema de automa√ß√£o acionar re-tentativas ou failover. No HDFS, a antecipa√ß√£o pode chegar a horas, permitindo realoca√ß√£o proativa de blocos de dados antes que falhas de disco se consumem.
</div>
</section>

<!-- 9. CONCLUS√ïES -->
<section>
<h2>9. Conclus√µes e Contribui√ß√µes</h2>

<h3>‚úÖ Contribui√ß√µes Positivas</h3>
<ol>
<li><strong>Valida√ß√£o do LogGPT como abordagem vi√°vel</strong> para detec√ß√£o proativa de anomalias em dois dom√≠nios (cloud computing e storage distribu√≠do).</li>
<li><strong>Capacidade de antecipa√ß√£o comprovada</strong>: o modelo n√£o apenas detecta, mas prev√™ falhas minutos ou horas antes de sua materializa√ß√£o.</li>
<li><strong>Pipeline reprodut√≠vel</strong>: todo o c√≥digo est√° documentado e dispon√≠vel para replica√ß√£o.</li>
<li><strong>An√°lise comparativa robusta</strong>: tr√™s datasets p√∫blicos testados, com m√©tricas completas e transparentes.</li>
</ol>

<h3>‚ö†Ô∏è Limita√ß√µes Identificadas</h3>
<ol>
<li><strong>Transfer√™ncia cross-domain limitada:</strong> O modelo treinado em um dom√≠nio (OpenStack) n√£o generaliza para hardware (BGL). √â necess√°rio re-treinar para novos dom√≠nios.</li>
<li><strong>Sensibilidade ao vocabul√°rio:</strong> A diversidade de templates impacta diretamente o desempenho. Datasets com muitos templates √∫nicos (&gt;100) s√£o desafiadores.</li>
<li><strong>Granularidade de sess√£o:</strong> A forma como os logs s√£o agrupados (sess√µes naturais vs. janelas deslizantes) afeta significativamente a qualidade da detec√ß√£o.</li>
</ol>

<h3>üîÆ Trabalhos Futuros</h3>
<ul>
<li>Retreinar o LogGPT diretamente em logs de BGL para avaliar se funciona com dados nativos do dom√≠nio.</li>
<li>Explorar embeddings de templates (Word2Vec, BERT) para melhorar a captura sem√¢ntica.</li>
<li>Implementar um sistema de re-treinamento cont√≠nuo (online learning) para adaptar o modelo a drift de vocabul√°rio.</li>
<li>Integrar com sistemas de orquestra√ß√£o (Kubernetes, Prometheus) para resposta autom√°tica.</li>
</ul>
</section>

<!-- 10. RESUMO FINAL -->
<section>
<h2>10. Tabela Resumo Final</h2>
<table>
<tr><th>Aspecto</th><th style="color:#27ae60">üü¢ OpenStack</th><th style="color:#3498db">üîµ HDFS</th><th style="color:#e74c3c">üî¥ BGL</th></tr>
<tr><td><strong>F1-Score</strong></td><td style="color:#27ae60;font-weight:bold">{OS['f1']*100:.1f}%</td><td style="color:#3498db;font-weight:bold">{HD['f1']*100:.1f}%</td><td style="color:#e74c3c;font-weight:bold">{BG['f1']*100:.1f}%</td></tr>
<tr><td><strong>Precision</strong></td><td>{OS['precision']*100:.1f}%</td><td>{HD['precision']*100:.1f}%</td><td>{BG['precision']*100:.1f}%</td></tr>
<tr><td><strong>Recall</strong></td><td>{OS['recall']*100:.1f}%</td><td>{HD['recall']*100:.1f}%</td><td>{BG['recall']*100:.0f}%</td></tr>
<tr><td><strong>Lead Time M√©dio</strong></td><td>{fmt(OS['lt_mean_min'])}</td><td>{fmt(HD['lt_mean_min'])}</td><td>N/A</td></tr>
<tr><td><strong>Templates</strong></td><td>{OS['n_templates']}</td><td>{HD['n_templates']}</td><td>{BG['n_templates']}</td></tr>
<tr><td><strong>Modelo</strong></td><td>Treinado local</td><td>Treinado local</td><td>Transfer (OpenStack)</td></tr>
<tr><td><strong>Veredicto</strong></td><td><span class="badge bg">‚úÖ Excelente</span></td><td><span class="badge bb">‚úÖ Bom</span></td><td><span class="badge br">‚ùå Insuficiente</span></td></tr>
</table>
</section>

</div>
</body></html>"""
