"""
Cria vocabul√°rio de templates do BGL para detec√ß√£o Top-K

Mapeia cada template √∫nico para um ID inteiro, permitindo:
1. Tokeniza√ß√£o ao n√≠vel de template (n√£o BPE)
2. Predi√ß√£o Top-K de pr√≥ximos templates
3. Vocabul√°rio reduzido (~242 templates vs 50k tokens BPE)
"""

import polars as pl
from pathlib import Path
import json

DATA_DIR = Path(r"D:\ProLog\data\BGL_sliding_windows")
OUTPUT_FILE = Path(r"D:\ProLog\bgl_template_vocab.json")

def build_template_vocab():
    """Constr√≥i vocabul√°rio de templates a partir dos dados BGL"""
    print("üî® Building BGL Template Vocabulary")
    print("=" * 60)
    
    # Carregar dados
    print("\nüìÇ Loading BGL data...")
    train_df = pl.read_parquet(DATA_DIR / "train.parquet")
    val_df = pl.read_parquet(DATA_DIR / "val.parquet")
    test_df = pl.read_parquet(DATA_DIR / "test.parquet")
    
    print(f"   Train: {len(train_df)} windows")
    print(f"   Val:   {len(val_df)} windows")
    print(f"   Test:  {len(test_df)} windows")
    
    # Coletar todos os templates √∫nicos
    print("\nüîç Collecting unique templates...")
    all_templates = set()
    
    for df in [train_df, val_df, test_df]:
        for row in df.iter_rows(named=True):
            sequence = row['sequence']
            all_templates.update(sequence)
    
    # Ordenar templates para consist√™ncia
    sorted_templates = sorted(all_templates)
    
    print(f"   Found {len(sorted_templates)} unique templates")
    
    # Criar mapeamento template ‚Üí ID
    template_to_id = {template: idx for idx, template in enumerate(sorted_templates)}
    id_to_template = {idx: template for template, idx in template_to_id.items()}
    
    # Adicionar tokens especiais
    vocab_size = len(sorted_templates)
    template_to_id["<PAD>"] = vocab_size
    template_to_id["<UNK>"] = vocab_size + 1
    id_to_template[vocab_size] = "<PAD>"
    id_to_template[vocab_size + 1] = "<UNK>"
    
    vocab_data = {
        "template_to_id": template_to_id,
        "id_to_template": id_to_template,
        "vocab_size": vocab_size + 2,  # +2 para <PAD> e <UNK>
        "num_real_templates": vocab_size
    }
    
    # Salvar vocabul√°rio
    print(f"\nüíæ Saving vocabulary to {OUTPUT_FILE}...")
    with open(OUTPUT_FILE, 'w', encoding='utf-8') as f:
        json.dump(vocab_data, f, indent=2, ensure_ascii=False)
    
    # Estat√≠sticas
    print("\nüìä Vocabulary Statistics:")
    print(f"   Total templates: {vocab_size}")
    print(f"   With special tokens: {vocab_size + 2}")
    print(f"   K (50% for Top-K): {vocab_size // 2}")
    
    # Mostrar exemplos
    print("\nüìù Sample templates (first 10):")
    for i, template in enumerate(sorted_templates[:10]):
        print(f"   ID {i}: {template}")
    
    print("\n‚úÖ Vocabulary created successfully!")
    return vocab_data

if __name__ == "__main__":
    vocab_data = build_template_vocab()
    print(f"\nüéØ K for Top-K detection: {vocab_data['num_real_templates'] // 2}")
