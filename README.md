# ðŸ“˜ LogGPT: Benchmarking e AnÃ¡lise de PrevisÃ£o de Falhas em Logs

> **Status do Projeto**: ðŸ”„ Fase 3 (HDFS Benchmark) em andamento.
> **Objetivo**: Validar a capacidade de modelos GPT (Next-Token Prediction) para antecipar falhas em sistemas distribuÃ­dos.

---

## ðŸ“‘ Ãndice
1.  [VisÃ£o Geral do Projeto](#-visÃ£o-geral-do-projeto)
2.  [Fase 1: ValidaÃ§Ã£o no OpenStack (Sucesso)](#-fase-1-validaÃ§Ã£o-no-openstack)
3.  [Fase 2: O Desafio do BGL (AnÃ¡lise CrÃ­tica)](#-fase-2-o-desafio-do-bgl)
4.  [Fase 3: HDFS Benchmark (Estado da Arte)](#-fase-3-hdfs-benchmark)
5.  [ReferÃªncias BibliogrÃ¡ficas](#-referÃªncias-bibliogrÃ¡ficas)
6.  [Estrutura do RepositÃ³rio](#-estrutura-do-repositÃ³rio)

---

## ï¿½ VisÃ£o Geral do Projeto

Este projeto investiga a aplicaÃ§Ã£o de Large Language Models (LLMs), especificamente a arquitetura **GPT-2**, para a anÃ¡lise de logs de sistemas. A hipÃ³tese central Ã© que logs de software estruturado possuem uma "gramÃ¡tica" previsÃ­vel, permitindo que modelos gerativos antecipem erros (Lead Time) ao detectar desvios na sequÃªncia esperada de eventos.

---

## âœ… Fase 1: ValidaÃ§Ã£o no OpenStack

**Objetivo**: Replicar os resultados do paper original LogGPT para garantir que nossa implementaÃ§Ã£o (LogGPT-Small) funciona.

### ðŸ”¬ Metodologia
*   **Dataset**: OpenStack (Logs de Cloud Management).
*   **Abordagem**: SessÃ£o por `Trace ID` (Logs agrupados por requisiÃ§Ã£o HTTP/VM).
*   **Modelo**: GPT-2 Small (4 layers, 256 embedding).

### ðŸ“ˆ Resultados
*   **F1-Score**: **96.6%**
*   **ConclusÃ£o**: O modelo aprendeu perfeitamente a sequÃªncia de provisionamento de VMs (`Create` -> `Allocate Network` -> `Success`). Quando a sequÃªncia quebra, a perplexidade sobe, detectando a anomalia.

---

## âš ï¸ Fase 2: O Desafio do BGL (BlueGene/L)

**Objetivo**: Aplicar a mesma lÃ³gica de "PrevisÃ£o de SessÃ£o" em logs de Supercomputadores (Hardware).

### âŒ O Problema
Ao tentar transferir o aprendizado do OpenStack para o BGL, encontramos uma barreira intransponÃ­vel para previsÃ£o pura:
1.  **AusÃªncia de SessÃ£o**: BGL nÃ£o tem `Trace ID`. Logs de hardware sÃ£o contÃ­nuos streams de milhares de componentes.
2.  **SessÃ£o Artificial (NodeID)**: Tentamos agrupar por NÃ³, mas isso cria "sessÃµes" de meses de duraÃ§Ã£o, sem inÃ­cio/fim claros.
3.  **Interleaving**: Eventos de falha (Hardware) acontecem aleatoriamente, sem uma cadeia causal de software anterior clara para o modelo "prever".

### ðŸ”Ž A Descoberta (Pesquisa)
Investigando a literatura para entender o fracasso, encontramos o paper **LogADEmpirical (ICSE 2022)**, que critica exatamente o que tentamos fazer.
*   *CitaÃ§Ã£o*: "Muitos benchmarks anteriores inflaram resultados no BGL usando janelas incorretas."
*   *Veredito*: BGL requer **Sliding Windows** (janelas deslizantes de tempo/contagem) e classificaÃ§Ã£o, nÃ£o previsÃ£o de sessÃ£o.

### ðŸ› ï¸ O PivÃ´ TÃ©cnico
Mudamos a estratÃ©gia no BGL para:
*   **Abordagem HÃ­brida**: Janelas de 20 eventos + DetecÃ§Ã£o de Anomalia por Top-K (Adaptive).
*   **Resultado**: Melhoramos a detecÃ§Ã£o, mas concluÃ­mos que BGL **nÃ£o Ã© adequado** para testar *PrevisÃ£o Generativa* (Lead Time).

---

## ðŸ”„ Fase 3: HDFS Benchmark (Hadoop Distributed File System)

**Objetivo**: Provar a capacidade de previsÃ£o (Lead Time) em um ambiente adequado (Software DistribuÃ­do).

### ðŸ’¡ Por que HDFS?
Baseado em **DeepLog (CCS'17)** e no prÃ³prio **LogGPT**, o HDFS Ã© o padrÃ£o-ouro para modelos sequenciais porque:
1.  **Processos de Software**: Segue mÃ¡quinas de estado finitas (`Allocation` -> `Packet` -> `Ack`).
2.  **SessÃ£o Nativa**: O `BlockId` isola cada transaÃ§Ã£o de arquivo, permitindo previsÃ£o contextual limpa.
3.  **Repetibilidade**: VocabulÃ¡rio pequeno (~46 templates), ideal para o GPT aprender a "rotina" normal.

### ðŸš€ Status Atual
*   **Preprocessing**: Reescrevemos o parser para ler logs brutos (1.5GB) usando Regex otimizado (Polars).
*   **ValidaÃ§Ã£o**: Pipeline testado com dataset dummy (FPR 0.18%).
*   **Bloqueio**: Aguardando download do Ground Truth (`anomaly_label.csv`) para calcular Recall real.

---

## ðŸ“š ReferÃªncias BibliogrÃ¡ficas

As decisÃµes tÃ©cnicas deste projeto foram embasadas nos seguintes papers:

1.  **LogGPT: Log Anomaly Detection via GPT** (Nokia, 2023)
    *   *Uso*: Base da arquitetura e hiperparÃ¢metros (Block Size=64, Embed=256). Valida uso de HDFS/OpenStack.
2.  **LogADEmpirical** (ICSE 2022)
    *   *Uso*: Foi crucial para entendermos por que nossa abordagem "Session-based" falhou no BGL e pivotarmos para Sliding Window.
3.  **DeepLog** (CCS 2017)
    *   *Uso*: Fundamentou a escolha do HDFS como o dataset ideal para testar modelos sequenciais (LSTM/Transformer).
4.  **Loghub** (GitHub Repo)
    *   *Uso*: Fonte dos datasets e templates de parsing.

---

## ðŸ“‚ Estrutura do RepositÃ³rio

```
D:\ProLog\
â”œâ”€â”€ 01_OpenStack_Validated\   # âœ… CÃ³digo validado (Fase 1)
â”œâ”€â”€ 03_HDFS_Benchmark\        # ðŸ”„ Pipeline HDFS atual (Fase 3)
â”œâ”€â”€ 05_loggpt_bgl\            # ðŸ§ª LaboratÃ³rio de Experimentos BGL (Fase 2)
â”‚   â”œâ”€â”€ reports\              # RelatÃ³rios detalhados da falha/pivÃ´ BGL
â”‚   â””â”€â”€ ...scripts...         # Scripts hÃ­bridos e window-based
â”œâ”€â”€ data\                     # Datasets Brutos
â””â”€â”€ README.md                 # Este documento
```
